{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "from sklearn import datasets"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"zDelAiF9xOJgpH2aFYGhyd",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"zr2ZKP7xQEj7U7vvXEplLV"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "help(datasets"
   ],
   "execution_count":4,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Help on package sklearn.datasets in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.datasets\n",
      "\n",
      "DESCRIPTION\n",
      "    The :mod:`sklearn.datasets` module includes utilities to load datasets,\n",
      "    including methods to load and fetch popular reference datasets. It also\n",
      "    features some artificial data generators.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _base\n",
      "    _california_housing\n",
      "    _covtype\n",
      "    _kddcup99\n",
      "    _lfw\n",
      "    _olivetti_faces\n",
      "    _openml\n",
      "    _rcv1\n",
      "    _samples_generator\n",
      "    _species_distributions\n",
      "    _svmlight_format_fast\n",
      "    _svmlight_format_io\n",
      "    _twenty_newsgroups\n",
      "    data (package)\n",
      "    descr (package)\n",
      "    images (package)\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clear_data_home(data_home=None)\n",
      "        Delete all the content of the data home cache.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            The path to scikit-learn data directory. If `None`, the default path\n",
      "            is `~\/sklearn_learn_data`.\n",
      "    \n",
      "    dump_svmlight_file(X, y, f, *, zero_based=True, comment=None, query_id=None, multilabel=False)\n",
      "        Dump the dataset in svmlight \/ libsvm file format.\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Training vectors, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "        \n",
      "        y : {array-like, sparse matrix}, shape = [n_samples (, n_labels)]\n",
      "            Target values. Class labels must be an\n",
      "            integer or float, or array-like objects of integer or float for\n",
      "            multilabel classifications.\n",
      "        \n",
      "        f : str or file-like in binary mode\n",
      "            If string, specifies the path that will contain the data.\n",
      "            If file-like, data will be written to f. f should be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        zero_based : boolean, default=True\n",
      "            Whether column indices should be written zero-based (True) or one-based\n",
      "            (False).\n",
      "        \n",
      "        comment : str, default=None\n",
      "            Comment to insert at the top of the file. This should be either a\n",
      "            Unicode string, which will be encoded as UTF-8, or an ASCII byte\n",
      "            string.\n",
      "            If a comment is given, then it will be preceded by one that identifies\n",
      "            the file as having been dumped by scikit-learn. Note that not all\n",
      "            tools grok comments in SVMlight files.\n",
      "        \n",
      "        query_id : array-like of shape (n_samples,), default=None\n",
      "            Array containing pairwise preference constraints (qid in svmlight\n",
      "            format).\n",
      "        \n",
      "        multilabel : boolean, default=False\n",
      "            Samples may have several labels each (see\n",
      "            https:\/\/www.csie.ntu.edu.tw\/~cjlin\/libsvmtools\/datasets\/multilabel.html)\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter *multilabel* to support multilabel datasets.\n",
      "    \n",
      "    fetch_20newsgroups(*, data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True, return_X_y=False)\n",
      "        Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality               1\n",
      "        Features                  text\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify a download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : {'train', 'test', 'all'}, default='train'\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        categories : array-like, dtype=str, default=None\n",
      "            If None (default), load all the categories.\n",
      "            If not None, list of category names to load (other categories\n",
      "            ignored).\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        remove : tuple, default=()\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "            'headers' follows an exact standard; the other filters are not always\n",
      "            correct.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns `(data.data, data.target)` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : list of shape (n_samples,)\n",
      "                The data list to learn.\n",
      "            target: ndarray of shape (n_samples,)\n",
      "                The target labels.\n",
      "            filenames: list of shape (n_samples,)\n",
      "                The path to the location of the data.\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            target_names: list of shape (n_classes,)\n",
      "                The names of target classes.\n",
      "        \n",
      "        (data, target) : tuple if `return_X_y=True`\n",
      "            .. versionadded:: 0.22\n",
      "    \n",
      "    fetch_20newsgroups_vectorized(*, subset='train', remove=(), data_home=None, download_if_missing=True, return_X_y=False, normalize=True, as_frame=False)\n",
      "        Load and vectorize the 20 newsgroups dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        This is a convenience function; the transformation is done using the\n",
      "        default settings for\n",
      "        :class:`~sklearn.feature_extraction.text.CountVectorizer`. For more\n",
      "        advanced usage (stopword filtering, n-gram extraction, etc.), combine\n",
      "        fetch_20newsgroups with a custom\n",
      "        :class:`~sklearn.feature_extraction.text.CountVectorizer`,\n",
      "        :class:`~sklearn.feature_extraction.text.HashingVectorizer`,\n",
      "        :class:`~sklearn.feature_extraction.text.TfidfTransformer` or\n",
      "        :class:`~sklearn.feature_extraction.text.TfidfVectorizer`.\n",
      "        \n",
      "        The resulting counts are normalized using\n",
      "        :func:`sklearn.preprocessing.normalize` unless normalize is set to False.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality          130107\n",
      "        Features                  real\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : {'train', 'test', 'all'}, default='train'\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        remove : tuple, default=()\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify an download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If True, normalizes each document's feature vector to unit norm using\n",
      "            :func:`sklearn.preprocessing.normalize`.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string, or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of\n",
      "            `target_columns`.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data: {sparse matrix, dataframe} of shape (n_samples, n_features)\n",
      "                The input data matrix. If ``as_frame`` is `True`, ``data`` is\n",
      "                a pandas DataFrame with sparse columns.\n",
      "            target: {ndarray, series} of shape (n_samples,)\n",
      "                The target labels. If ``as_frame`` is `True`, ``target`` is a\n",
      "                pandas Series.\n",
      "            target_names: list of shape (n_classes,)\n",
      "                The names of target classes.\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            frame: dataframe of shape (n_samples, n_features + 1)\n",
      "                Only present when `as_frame=True`. Pandas DataFrame with ``data``\n",
      "                and ``target``.\n",
      "        \n",
      "                .. versionadded:: 0.24\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            `data` and `target` would be of the format defined in the `Bunch`\n",
      "            description above.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_california_housing(*, data_home=None, download_if_missing=True, return_X_y=False, as_frame=False)\n",
      "        Load the California housing dataset (regression).\n",
      "        \n",
      "        ==============   ==============\n",
      "        Samples total             20640\n",
      "        Dimensionality                8\n",
      "        Features                   real\n",
      "        Target           real 0.15 - 5.\n",
      "        ==============   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <california_housing_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        \n",
      "        return_X_y : bool, default=False.\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target_columns.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray, shape (20640, 8)\n",
      "                Each row corresponding to the 8 feature values in order.\n",
      "                If ``as_frame`` is True, ``data`` is a pandas object.\n",
      "            target : numpy array of shape (20640,)\n",
      "                Each value corresponds to the average\n",
      "                house value in units of 100,000.\n",
      "                If ``as_frame`` is True, ``target`` is a pandas object.\n",
      "            feature_names : list of length 8\n",
      "                Array of ordered feature names used in the dataset.\n",
      "            DESCR : str\n",
      "                Description of the California housing dataset.\n",
      "            frame : pandas DataFrame\n",
      "                Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "                ``target``.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset consists of 20,640 samples and 9 features.\n",
      "    \n",
      "    fetch_covtype(*, data_home=None, download_if_missing=True, random_state=None, shuffle=False, return_X_y=False, as_frame=False)\n",
      "        Load the covertype dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ============\n",
      "        Classes                        7\n",
      "        Samples total             581012\n",
      "        Dimensionality                54\n",
      "        Features                     int\n",
      "        =================   ============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <covtype_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is a pandas DataFrame or\n",
      "            Series depending on the number of target columns. If `return_X_y` is\n",
      "            True, then (`data`, `target`) will be pandas DataFrames or Series as\n",
      "            described below.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray of shape (581012, 54)\n",
      "                Each row corresponds to the 54 features in the dataset.\n",
      "            target : ndarray of shape (581012,)\n",
      "                Each value corresponds to one of\n",
      "                the 7 forest covertypes with values\n",
      "                ranging between 1 to 7.\n",
      "            frame : dataframe of shape (581012, 55)\n",
      "                Only present when `as_frame=True`. Contains `data` and `target`.\n",
      "            DESCR : str\n",
      "                Description of the forest covertype dataset.\n",
      "            feature_names : list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of the target columns.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_kddcup99(*, subset=None, data_home=None, shuffle=False, random_state=None, percent10=True, download_if_missing=True, return_X_y=False, as_frame=False)\n",
      "        Load the kddcup99 dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ====================================\n",
      "        Classes                                               23\n",
      "        Samples total                                    4898431\n",
      "        Dimensionality                                        41\n",
      "        Features            discrete (int) or continuous (float)\n",
      "        =================   ====================================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <kddcup99_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : {'SA', 'SF', 'http', 'smtp'}, default=None\n",
      "            To return the corresponding classical subsets of kddcup 99.\n",
      "            If None, return the entire kddcup 99 dataset.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling and for\n",
      "            selection of abnormal samples if `subset='SA'`. Pass an int for\n",
      "            reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        percent10 : bool, default=True\n",
      "            Whether to load only 10 percent of the data.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If `True`, returns a pandas Dataframe for the ``data`` and ``target``\n",
      "            objects in the `Bunch` returned object; `Bunch` return object will also\n",
      "            have a ``frame`` member.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (494021, 41)\n",
      "                The data matrix to learn. If `as_frame=True`, `data` will be a\n",
      "                pandas DataFrame.\n",
      "            target : {ndarray, series} of shape (494021,)\n",
      "                The regression target for each sample. If `as_frame=True`, `target`\n",
      "                will be a pandas Series.\n",
      "            frame : dataframe of shape (494021, 42)\n",
      "                Only present when `as_frame=True`. Contains `data` and `target`.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            feature_names : list\n",
      "                The names of the dataset columns\n",
      "            target_names: list\n",
      "                The names of the target columns\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_lfw_pairs(*, subset='train', data_home=None, funneled=True, resize=0.5, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True)\n",
      "        Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                   2\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        In the official `README.txt`_ this task is described as the\n",
      "        \"Restricted\" task.  As I am not sure as to implement the\n",
      "        \"Unrestricted\" variant correctly, I left it as unsupported for now.\n",
      "        \n",
      "          .. _`README.txt`: http:\/\/vis-www.cs.umass.edu\/lfw\/README.txt\n",
      "        \n",
      "        The original images are 250 x 250 pixels, but the default slice and resize\n",
      "        arguments reduce them to 62 x 47.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : {'train', 'test', '10_folds'}, default='train'\n",
      "            Select the dataset to load: 'train' for the development training\n",
      "            set, 'test' for the development test set, and '10_folds' for the\n",
      "            official evaluation set that is meant to be used with a 10-folds\n",
      "            cross validation.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By\n",
      "            default all scikit-learn data is stored in '~\/scikit_learn_data'\n",
      "            subfolders.\n",
      "        \n",
      "        funneled : bool, default=True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, default=0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        color : bool, default=False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : tuple of slice, default=(slice(70, 195), slice(78, 172))\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray of shape (2200, 5828). Shape depends on ``subset``.\n",
      "                Each row corresponds to 2 ravel'd face images\n",
      "                of original size 62 x 47 pixels.\n",
      "                Changing the ``slice_``, ``resize`` or ``subset`` parameters\n",
      "                will change the shape of the output.\n",
      "            pairs : ndarray of shape (2200, 2, 62, 47). Shape depends on ``subset``\n",
      "                Each row has 2 face images corresponding\n",
      "                to same or different person from the dataset\n",
      "                containing 5749 people. Changing the ``slice_``,\n",
      "                ``resize`` or ``subset`` parameters will change the shape of the\n",
      "                output.\n",
      "            target : numpy array of shape (2200,). Shape depends on ``subset``.\n",
      "                Labels associated to each pair of images.\n",
      "                The two label values being different persons or the same person.\n",
      "            DESCR : str\n",
      "                Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "    \n",
      "    fetch_lfw_people(*, data_home=None, funneled=True, resize=0.5, min_faces_per_person=0, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True, return_X_y=False)\n",
      "        Load the Labeled Faces in the Wild (LFW) people dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                5749\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        funneled : bool, default=True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, default=0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        min_faces_per_person : int, default=None\n",
      "            The extracted dataset will only retain pictures of people that have at\n",
      "            least `min_faces_per_person` different pictures.\n",
      "        \n",
      "        color : bool, default=False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : tuple of slice, default=(slice(70, 195), slice(78, 172))\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : numpy array of shape (13233, 2914)\n",
      "                Each row corresponds to a ravelled face image\n",
      "                of original size 62 x 47 pixels.\n",
      "                Changing the ``slice_`` or resize parameters will change the\n",
      "                shape of the output.\n",
      "            images : numpy array of shape (13233, 62, 47)\n",
      "                Each row is a face image corresponding to one of the 5749 people in\n",
      "                the dataset. Changing the ``slice_``\n",
      "                or resize parameters will change the shape of the output.\n",
      "            target : numpy array of shape (13233,)\n",
      "                Labels associated to each face image.\n",
      "                Those labels range from 0-5748 and correspond to the person IDs.\n",
      "            DESCR : str\n",
      "                Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_olivetti_faces(*, data_home=None, shuffle=False, random_state=0, download_if_missing=True, return_X_y=False)\n",
      "        Load the Olivetti faces data-set from AT&T (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                                40\n",
      "        Samples total                         400\n",
      "        Dimensionality                       4096\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <olivetti_faces_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            If True the order of the dataset is shuffled to avoid having\n",
      "            images of the same person grouped.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=0\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns `(data, target)` instead of a `Bunch` object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data: ndarray, shape (400, 4096)\n",
      "                Each row corresponds to a ravelled\n",
      "                face image of original size 64 x 64 pixels.\n",
      "            images : ndarray, shape (400, 64, 64)\n",
      "                Each row is a face image\n",
      "                corresponding to one of the 40 subjects of the dataset.\n",
      "            target : ndarray, shape (400,)\n",
      "                Labels associated to each face image.\n",
      "                Those labels are ranging from 0-39 and correspond to the\n",
      "                Subject IDs.\n",
      "            DESCR : str\n",
      "                Description of the modified Olivetti Faces Dataset.\n",
      "        \n",
      "        (data, target) : tuple if `return_X_y=True`\n",
      "            .. versionadded:: 0.22\n",
      "    \n",
      "    fetch_openml(name: Union[str, NoneType] = None, *, version: Union[str, int] = 'active', data_id: Union[int, NoneType] = None, data_home: Union[str, NoneType] = None, target_column: Union[str, List, NoneType] = 'default-target', cache: bool = True, return_X_y: bool = False, as_frame: Union[str, bool] = 'auto')\n",
      "        Fetch dataset from openml by name or dataset id.\n",
      "        \n",
      "        Datasets are uniquely identified by either an integer ID or by a\n",
      "        combination of name and version (i.e. there might be multiple\n",
      "        versions of the 'iris' dataset). Please give either name or data_id\n",
      "        (not both). In case a name is given, a version can also be\n",
      "        provided.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <openml>`.\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "        \n",
      "        .. note:: EXPERIMENTAL\n",
      "        \n",
      "            The API is experimental (particularly the return value structure),\n",
      "            and might have small backward-incompatible changes without notice\n",
      "            or warning in future releases.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : str, default=None\n",
      "            String identifier of the dataset. Note that OpenML can have multiple\n",
      "            datasets with the same name.\n",
      "        \n",
      "        version : int or 'active', default='active'\n",
      "            Version of the dataset. Can only be provided if also ``name`` is given.\n",
      "            If 'active' the oldest version that's still active is used. Since\n",
      "            there may be more than one active version of a dataset, and those\n",
      "            versions may fundamentally be different from one another, setting an\n",
      "            exact version is highly recommended.\n",
      "        \n",
      "        data_id : int, default=None\n",
      "            OpenML ID of the dataset. The most specific way of retrieving a\n",
      "            dataset. If data_id is not given, name (and potential version) are\n",
      "            used to obtain a dataset.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the data sets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        target_column : str, list or None, default='default-target'\n",
      "            Specify the column name in the data to use as target. If\n",
      "            'default-target', the standard target column a stored on the server\n",
      "            is used. If ``None``, all columns are returned as data and the\n",
      "            target is ``None``. If list (of strings), all columns with these names\n",
      "            are returned as multi-target (Note: not all scikit-learn classifiers\n",
      "            can handle all types of multi-output combinations)\n",
      "        \n",
      "        cache : bool, default=True\n",
      "            Whether to cache downloaded datasets using joblib.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` objects.\n",
      "        \n",
      "        as_frame : bool or 'auto', default='auto'\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target_columns.\n",
      "            The Bunch will contain a ``frame`` attribute with the target and the\n",
      "            data. If ``return_X_y`` is True, then ``(data, target)`` will be pandas\n",
      "            DataFrames or Series as describe above.\n",
      "        \n",
      "            If as_frame is 'auto', the data and target will be converted to\n",
      "            DataFrame or Series as if as_frame is set to True, unless the dataset\n",
      "            is stored in sparse format.\n",
      "        \n",
      "            .. versionchanged:: 0.24\n",
      "               The default value of `as_frame` changed from `False` to `'auto'`\n",
      "               in 0.24.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        \n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : np.array, scipy.sparse.csr_matrix of floats, or pandas DataFrame\n",
      "                The feature matrix. Categorical features are encoded as ordinals.\n",
      "            target : np.array, pandas Series or DataFrame\n",
      "                The regression target or classification labels, if applicable.\n",
      "                Dtype is float if numeric, and object if categorical. If\n",
      "                ``as_frame`` is True, ``target`` is a pandas object.\n",
      "            DESCR : str\n",
      "                The full description of the dataset\n",
      "            feature_names : list\n",
      "                The names of the dataset columns\n",
      "            target_names: list\n",
      "                The names of the target columns\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "            categories : dict or None\n",
      "                Maps each categorical feature name to a list of values, such\n",
      "                that the value encoded as i is ith in the list. If ``as_frame``\n",
      "                is True, this is None.\n",
      "            details : dict\n",
      "                More metadata from OpenML\n",
      "            frame : pandas DataFrame\n",
      "                Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "                ``target``.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. note:: EXPERIMENTAL\n",
      "        \n",
      "                This interface is **experimental** and subsequent releases may\n",
      "                change attributes without notice (although there should only be\n",
      "                minor changes to ``data`` and ``target``).\n",
      "        \n",
      "            Missing values in the 'data' are represented as NaN's. Missing values\n",
      "            in 'target' are represented as NaN's (numerical target) or None\n",
      "            (categorical target)\n",
      "    \n",
      "    fetch_rcv1(*, data_home=None, subset='all', download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "        Load the RCV1 multilabel dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        Version: RCV1-v2, vectors, full sets, topics multilabels.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                               103\n",
      "        Samples total                      804414\n",
      "        Dimensionality                      47236\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <rcv1_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.17\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : {'train', 'test', 'all'}, default='all'\n",
      "            Select the dataset to load: 'train' for the training set\n",
      "            (23149 samples), 'test' for the test set (781265 samples),\n",
      "            'all' for both, with the training samples first if shuffle is False.\n",
      "            This follows the official LYRL2004 chronological split.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : sparse matrix of shape (804414, 47236), dtype=np.float64\n",
      "                The array has 0.16% of non zero values. Will be of CSR format.\n",
      "            target : sparse matrix of shape (804414, 103), dtype=np.uint8\n",
      "                Each sample has a value of 1 in its categories, and 0 in others.\n",
      "                The array has 3.15% of non zero values. Will be of CSR format.\n",
      "            sample_id : ndarray of shape (804414,), dtype=np.uint32,\n",
      "                Identification number of each sample, as ordered in dataset.data.\n",
      "            target_names : ndarray of shape (103,), dtype=object\n",
      "                Names of each target (RCV1 topics), as ordered in dataset.target.\n",
      "            DESCR : str\n",
      "                Description of the RCV1 dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_species_distributions(*, data_home=None, download_if_missing=True)\n",
      "        Loader for species distribution dataset from Phillips et. al. (2006)\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~\/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            coverages : array, shape = [14, 1592, 1212]\n",
      "                These represent the 14 features measured\n",
      "                at each point of the map grid.\n",
      "                The latitude\/longitude values for the grid are discussed below.\n",
      "                Missing data is represented by the value -9999.\n",
      "            train : record array, shape = (1624,)\n",
      "                The training points for the data.  Each point has three fields:\n",
      "        \n",
      "                - train['species'] is the species name\n",
      "                - train['dd long'] is the longitude, in degrees\n",
      "                - train['dd lat'] is the latitude, in degrees\n",
      "            test : record array, shape = (620,)\n",
      "                The test points for the data.  Same format as the training data.\n",
      "            Nx, Ny : integers\n",
      "                The number of longitudes (x) and latitudes (y) in the grid\n",
      "            x_left_lower_corner, y_left_lower_corner : floats\n",
      "                The (x,y) position of the lower-left corner, in degrees\n",
      "            grid_size : float\n",
      "                The spacing between points of the grid, in degrees\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        * `\"Maximum entropy modeling of species geographic distributions\"\n",
      "          <http:\/\/rob.schapire.net\/papers\/ecolmod.pdf>`_\n",
      "          S. J. Phillips, R. P. Anderson, R. E. Schapire - Ecological Modelling,\n",
      "          190:231-259, 2006.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset represents the geographic distribution of species.\n",
      "        The dataset is provided by Phillips et. al. (2006).\n",
      "        \n",
      "        The two species are:\n",
      "        \n",
      "        - `\"Bradypus variegatus\"\n",
      "          <http:\/\/www.iucnredlist.org\/details\/3038\/0>`_ ,\n",
      "          the Brown-throated Sloth.\n",
      "        \n",
      "        - `\"Microryzomys minutus\"\n",
      "          <http:\/\/www.iucnredlist.org\/details\/13408\/0>`_ ,\n",
      "          also known as the Forest Small Rice Rat, a rodent that lives in Peru,\n",
      "          Colombia, Ecuador, Peru, and Venezuela.\n",
      "        \n",
      "        - For an example of using this dataset with scikit-learn, see\n",
      "          :ref:`examples\/applications\/plot_species_distribution_modeling.py\n",
      "          <sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py>`.\n",
      "    \n",
      "    get_data_home(data_home=None) -> str\n",
      "        Return the path of the scikit-learn data dir.\n",
      "        \n",
      "        This folder is used by some large dataset loaders to avoid downloading the\n",
      "        data several times.\n",
      "        \n",
      "        By default the data dir is set to a folder named 'scikit_learn_data' in the\n",
      "        user home folder.\n",
      "        \n",
      "        Alternatively, it can be set by the 'SCIKIT_LEARN_DATA' environment\n",
      "        variable or programmatically by giving an explicit folder path. The '~'\n",
      "        symbol is expanded to the user home folder.\n",
      "        \n",
      "        If the folder does not already exist, it is automatically created.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            The path to scikit-learn data directory. If `None`, the default path\n",
      "            is `~\/sklearn_learn_data`.\n",
      "    \n",
      "    load_boston(*, return_X_y=False)\n",
      "        DEPRECATED: `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "        \n",
      "        The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "        the documentation of this function for further details.\n",
      "        \n",
      "        The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "        dataset unless the purpose of the code is to study and educate about\n",
      "        ethical issues in data science and machine learning.\n",
      "        \n",
      "        In this special case, you can fetch the dataset from the original\n",
      "        source::\n",
      "        \n",
      "            import pandas as pd\n",
      "            import numpy as np\n",
      "        \n",
      "        \n",
      "            data_url = \"http:\/\/lib.stat.cmu.edu\/datasets\/boston\"\n",
      "            raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "            data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "            target = raw_df.values[1::2, 2]\n",
      "        \n",
      "        Alternative datasets include the California housing dataset (i.e.\n",
      "        :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "        dataset. You can load the datasets as follows::\n",
      "        \n",
      "            from sklearn.datasets import fetch_california_housing\n",
      "            housing = fetch_california_housing()\n",
      "        \n",
      "        for the California housing dataset and::\n",
      "        \n",
      "            from sklearn.datasets import fetch_openml\n",
      "            housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "        \n",
      "        for the Ames housing dataset.\n",
      "        \n",
      "        \n",
      "        Load and return the boston house-prices dataset (regression).\n",
      "        \n",
      "        ==============   ==============\n",
      "        Samples total               506\n",
      "        Dimensionality               13\n",
      "        Features         real, positive\n",
      "        Targets           real 5. - 50.\n",
      "        ==============   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "        \n",
      "        .. deprecated:: 1.0\n",
      "           This function is deprecated in 1.0 and will be removed in 1.2. See the\n",
      "           warning message below for further details regarding the alternative\n",
      "           datasets.\n",
      "        \n",
      "        .. warning::\n",
      "            The Boston housing prices dataset has an ethical problem: as\n",
      "            investigated in [1]_, the authors of this dataset engineered a\n",
      "            non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "            positive impact on house prices [2]_. Furthermore the goal of the\n",
      "            research that led to the creation of this dataset was to study the\n",
      "            impact of air quality but it did not give adequate demonstration of the\n",
      "            validity of this assumption.\n",
      "        \n",
      "            The scikit-learn maintainers therefore strongly discourage the use of\n",
      "            this dataset unless the purpose of the code is to study and educate\n",
      "            about ethical issues in data science and machine learning.\n",
      "        \n",
      "            In this special case, you can fetch the dataset from the original\n",
      "            source::\n",
      "        \n",
      "                import pandas as pd  # doctest: +SKIP\n",
      "                import numpy as np\n",
      "        \n",
      "        \n",
      "                data_url = \"http:\/\/lib.stat.cmu.edu\/datasets\/boston\"\n",
      "                raw_df = pd.read_csv(data_url, sep=\"s+\", skiprows=22, header=None)\n",
      "                data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "                target = raw_df.values[1::2, 2]\n",
      "        \n",
      "            Alternative datasets include the California housing dataset [3]_\n",
      "            (i.e. :func:`~sklearn.datasets.fetch_california_housing`) and Ames\n",
      "            housing dataset [4]_. You can load the datasets as follows::\n",
      "        \n",
      "                from sklearn.datasets import fetch_california_housing\n",
      "                housing = fetch_california_housing()\n",
      "        \n",
      "            for the California housing dataset and::\n",
      "        \n",
      "                from sklearn.datasets import fetch_openml\n",
      "                housing = fetch_openml(name=\"house_prices\", as_frame=True)  # noqa\n",
      "        \n",
      "            for the Ames housing dataset.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray of shape (506, 13)\n",
      "                The data matrix.\n",
      "            target : ndarray of shape (506,)\n",
      "                The regression target.\n",
      "            filename : str\n",
      "                The physical location of boston csv dataset.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            feature_names : ndarray\n",
      "                The names of features\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed a wrong data point at [445, 0].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Racist data destruction? M Carlisle,\n",
      "                <https:\/\/medium.com\/@docintangible\/racist-data-destruction-113e3eff54a8>`_\n",
      "        .. [2] `Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "               \"Hedonic housing prices and the demand for clean air.\"\n",
      "               Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "               <https:\/\/www.researchgate.net\/publication\/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>`_\n",
      "        .. [3] `California housing dataset\n",
      "                <https:\/\/scikit-learn.org\/stable\/datasets\/real_world.html#california-housing-dataset>`_\n",
      "        .. [4] `Ames housing dataset\n",
      "                <https:\/\/www.openml.org\/d\/42165>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import warnings\n",
      "        >>> from sklearn.datasets import load_boston\n",
      "        >>> with warnings.catch_warnings():\n",
      "        ...     # You should probably not use this dataset.\n",
      "        ...     warnings.filterwarnings(\"ignore\")\n",
      "        ...     X, y = load_boston(return_X_y=True)\n",
      "        >>> print(X.shape)\n",
      "        (506, 13)\n",
      "    \n",
      "    load_breast_cancer(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the breast cancer wisconsin dataset (classification).\n",
      "        \n",
      "        The breast cancer dataset is a classic and very easy binary classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          2\n",
      "        Samples per class    212(M),357(B)\n",
      "        Samples total                  569\n",
      "        Dimensionality                  30\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <breast_cancer_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (569, 30)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (569,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "            frame: DataFrame of shape (569, 31)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            filename: str\n",
      "                The path to the location of the data.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        The copy of UCI ML Breast Cancer Wisconsin (Diagnostic) dataset is\n",
      "        downloaded from:\n",
      "        https:\/\/goo.gl\/U2Uwz2\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 50, and 85, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_breast_cancer\n",
      "        >>> data = load_breast_cancer()\n",
      "        >>> data.target[[10, 50, 85]]\n",
      "        array([0, 1, 0])\n",
      "        >>> list(data.target_names)\n",
      "        ['malignant', 'benign']\n",
      "    \n",
      "    load_diabetes(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the diabetes dataset (regression).\n",
      "        \n",
      "        ==============   ==================\n",
      "        Samples total    442\n",
      "        Dimensionality   10\n",
      "        Features         real, -.2 < x < .2\n",
      "        Targets          integer 25 - 346\n",
      "        ==============   ==================\n",
      "        \n",
      "        .. note::\n",
      "           The meaning of each feature (i.e. `feature_names`) might be unclear\n",
      "           (especially for `ltg`) as the documentation of the original dataset is\n",
      "           not explicit. We provide information that seems correct in regard with\n",
      "           the scientific literature in this field of research.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (442, 10)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (442,)\n",
      "                The regression target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            frame: DataFrame of shape (442, 11)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            data_filename: str\n",
      "                The path to the location of the data.\n",
      "            target_filename: str\n",
      "                The path to the location of the target.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_digits(*, n_class=10, return_X_y=False, as_frame=False)\n",
      "        Load and return the digits dataset (classification).\n",
      "        \n",
      "        Each datapoint is a 8x8 image of a digit.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                         10\n",
      "        Samples per class             ~180\n",
      "        Samples total                 1797\n",
      "        Dimensionality                  64\n",
      "        Features             integers 0-16\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <digits_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_class : int, default=10\n",
      "            The number of classes to return. Between 0 and 10.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (1797, 64)\n",
      "                The flattened data matrix. If `as_frame=True`, `data` will be\n",
      "                a pandas DataFrame.\n",
      "            target: {ndarray, Series} of shape (1797,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "            frame: DataFrame of shape (1797, 65)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            images: {ndarray} of shape (1797, 8, 8)\n",
      "                The raw image data.\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "        https:\/\/archive.ics.uci.edu\/ml\/datasets\/Optical+Recognition+of+Handwritten+Digits\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images::\n",
      "        \n",
      "            >>> from sklearn.datasets import load_digits\n",
      "            >>> digits = load_digits()\n",
      "            >>> print(digits.data.shape)\n",
      "            (1797, 64)\n",
      "            >>> import matplotlib.pyplot as plt\n",
      "            >>> plt.gray()\n",
      "            >>> plt.matshow(digits.images[0])\n",
      "            <...>\n",
      "            >>> plt.show()\n",
      "    \n",
      "    load_files(container_path, *, description=None, categories=None, load_content=True, shuffle=True, encoding=None, decode_error='strict', random_state=0)\n",
      "        Load text files with categories as subfolder names.\n",
      "        \n",
      "        Individual samples are assumed to be files stored a two levels folder\n",
      "        structure such as the following:\n",
      "        \n",
      "            container_folder\/\n",
      "                category_1_folder\/\n",
      "                    file_1.txt\n",
      "                    file_2.txt\n",
      "                    ...\n",
      "                    file_42.txt\n",
      "                category_2_folder\/\n",
      "                    file_43.txt\n",
      "                    file_44.txt\n",
      "                    ...\n",
      "        \n",
      "        The folder names are used as supervised signal label names. The individual\n",
      "        file names are not important.\n",
      "        \n",
      "        This function does not try to extract features into a numpy array or scipy\n",
      "        sparse matrix. In addition, if load_content is false it does not try to\n",
      "        load the files in memory.\n",
      "        \n",
      "        To use text files in a scikit-learn classification or clustering algorithm,\n",
      "        you will need to use the :mod`~sklearn.feature_extraction.text` module to\n",
      "        build a feature extraction transformer that suits your problem.\n",
      "        \n",
      "        If you set load_content=True, you should also specify the encoding of the\n",
      "        text using the 'encoding' parameter. For many modern text files, 'utf-8'\n",
      "        will be the correct encoding. If you leave encoding equal to None, then the\n",
      "        content will be made of bytes instead of Unicode, and you will not be able\n",
      "        to use most functions in :mod:`~sklearn.feature_extraction.text`.\n",
      "        \n",
      "        Similar feature extractors should be built for other kind of unstructured\n",
      "        data input such as images, audio, video, ...\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        container_path : str\n",
      "            Path to the main folder holding one subfolder per category\n",
      "        \n",
      "        description : str, default=None\n",
      "            A paragraph describing the characteristic of the dataset: its source,\n",
      "            reference, etc.\n",
      "        \n",
      "        categories : list of str, default=None\n",
      "            If None (default), load all the categories. If not None, list of\n",
      "            category names to load (other categories ignored).\n",
      "        \n",
      "        load_content : bool, default=True\n",
      "            Whether to load or not the content of the different files. If true a\n",
      "            'data' attribute containing the text information is present in the data\n",
      "            structure returned. If not, a filenames attribute gives the path to the\n",
      "            files.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        encoding : str, default=None\n",
      "            If None, do not try to decode the content of the files (e.g. for images\n",
      "            or other non-text content). If not None, encoding to use to decode text\n",
      "            files to Unicode if load_content is True.\n",
      "        \n",
      "        decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n",
      "            Instruction on what to do if a byte sequence is given to analyze that\n",
      "            contains characters not of the given `encoding`. Passed as keyword\n",
      "            argument 'errors' to bytes.decode.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=0\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : list of str\n",
      "                Only present when `load_content=True`.\n",
      "                The raw text data to learn.\n",
      "            target : ndarray\n",
      "                The target labels (integer index).\n",
      "            target_names : list\n",
      "                The names of target classes.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            filenames: ndarray\n",
      "                The filenames holding the dataset.\n",
      "    \n",
      "    load_iris(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the iris dataset (classification).\n",
      "        \n",
      "        The iris dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class               50\n",
      "        Samples total                  150\n",
      "        Dimensionality                   4\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <iris_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (150, 4)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (150,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "            frame: DataFrame of shape (150, 5)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            filename: str\n",
      "                The path to the location of the data.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed two wrong data points according to Fisher's paper.\n",
      "                The new version is the same as in R, but not as in the UCI\n",
      "                Machine Learning Repository.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 25, and 50, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_iris\n",
      "        >>> data = load_iris()\n",
      "        >>> data.target[[10, 25, 50]]\n",
      "        array([0, 0, 1])\n",
      "        >>> list(data.target_names)\n",
      "        ['setosa', 'versicolor', 'virginica']\n",
      "    \n",
      "    load_linnerud(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the physical exercise Linnerud dataset.\n",
      "        \n",
      "        This dataset is suitable for multi-ouput regression tasks.\n",
      "        \n",
      "        ==============   ============================\n",
      "        Samples total    20\n",
      "        Dimensionality   3 (for both data and target)\n",
      "        Features         integer\n",
      "        Targets          integer\n",
      "        ==============   ============================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <linnerrud_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (20, 3)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, dataframe} of shape (20, 3)\n",
      "                The regression targets. If `as_frame=True`, `target` will be\n",
      "                a pandas DataFrame.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of the target columns.\n",
      "            frame: DataFrame of shape (20, 6)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            data_filename: str\n",
      "                The path to the location of the data.\n",
      "            target_filename: str\n",
      "                The path to the location of the target.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_sample_image(image_name)\n",
      "        Load the numpy array of a single sample image\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        image_name : {`china.jpg`, `flower.jpg`}\n",
      "            The name of the sample image loaded\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        img : 3D array\n",
      "            The image as a numpy array: height x width x color\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_image\n",
      "        >>> china = load_sample_image('china.jpg')   # doctest: +SKIP\n",
      "        >>> china.dtype                              # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> china.shape                              # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> flower = load_sample_image('flower.jpg') # doctest: +SKIP\n",
      "        >>> flower.dtype                             # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> flower.shape                             # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "    \n",
      "    load_sample_images()\n",
      "        Load sample images for image manipulation.\n",
      "        \n",
      "        Loads both, ``china`` and ``flower``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            images : list of ndarray of shape (427, 640, 3)\n",
      "                The two sample image.\n",
      "            filenames : list\n",
      "                The filenames for the images.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images:\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_images\n",
      "        >>> dataset = load_sample_images()     #doctest: +SKIP\n",
      "        >>> len(dataset.images)                #doctest: +SKIP\n",
      "        2\n",
      "        >>> first_img_data = dataset.images[0] #doctest: +SKIP\n",
      "        >>> first_img_data.shape               #doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> first_img_data.dtype               #doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "    \n",
      "    load_svmlight_file(f, *, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load datasets in the svmlight \/ libsvm format into sparse CSR matrix\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        This format is used as the default format for both svmlight and the\n",
      "        libsvm command line programs.\n",
      "        \n",
      "        Parsing a text based source can be expensive. When repeatedly\n",
      "        working on the same dataset, it is recommended to wrap this\n",
      "        loader with joblib.Memory.cache to store a memmapped backup of the\n",
      "        CSR results of the first call and benefit from the near instantaneous\n",
      "        loading of memmapped structures for the subsequent calls.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        This implementation is written in Cython and is reasonably fast.\n",
      "        However, a faster API-compatible loader is also available at:\n",
      "        \n",
      "          https:\/\/github.com\/mblondel\/svmlight-loader\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f : str, file-like or int\n",
      "            (Path to) a file to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. A file-like or file descriptor will not be closed\n",
      "            by this function. A file-like object must be opened in binary mode.\n",
      "        \n",
      "        n_features : int, default=None\n",
      "            The number of features to use. If None, it will be inferred. This\n",
      "            argument is useful to load several files that are subsets of a\n",
      "            bigger sliced dataset: each subset might not have examples of\n",
      "            every feature, hence the inferred shape might vary from one\n",
      "            slice to another.\n",
      "            n_features is only required if ``offset`` or ``length`` are passed a\n",
      "            non-default value.\n",
      "        \n",
      "        dtype : numpy data type, default=np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : bool, default=False\n",
      "            Samples may have several labels each (see\n",
      "            https:\/\/www.csie.ntu.edu.tw\/~cjlin\/libsvmtools\/datasets\/multilabel.html)\n",
      "        \n",
      "        zero_based : bool or \"auto\", default=\"auto\"\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python\/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no ``offset`` or ``length`` is passed.\n",
      "            If ``offset`` or ``length`` are passed, the \"auto\" mode falls back\n",
      "            to ``zero_based=True`` to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : bool, default=False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : int, default=0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : int, default=-1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : scipy.sparse matrix of shape (n_samples, n_features)\n",
      "        \n",
      "        y : ndarray of shape (n_samples,), or, in the multilabel a list of\n",
      "            tuples of length n_samples.\n",
      "        \n",
      "        query_id : array of shape (n_samples,)\n",
      "           query_id for each sample. Only returned when query_id is set to\n",
      "           True.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        load_svmlight_files : Similar function for loading multiple files in this\n",
      "            format, enforcing the same number of features\/columns on all of them.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To use joblib.Memory to cache the svmlight file::\n",
      "        \n",
      "            from joblib import Memory\n",
      "            from .datasets import load_svmlight_file\n",
      "            mem = Memory(\".\/mycache\")\n",
      "        \n",
      "            @mem.cache\n",
      "            def get_data():\n",
      "                data = load_svmlight_file(\"mysvmlightfile\")\n",
      "                return data[0], data[1]\n",
      "        \n",
      "            X, y = get_data()\n",
      "    \n",
      "    load_svmlight_files(files, *, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load dataset from multiple files in SVMlight format\n",
      "        \n",
      "        This function is equivalent to mapping load_svmlight_file over a list of\n",
      "        files, except that the results are concatenated into a single, flat list\n",
      "        and the samples vectors are constrained to all have the same number of\n",
      "        features.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        files : array-like, dtype=str, file-like or int\n",
      "            (Paths of) files to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. File-likes and file descriptors will not be\n",
      "            closed by this function. File-like objects must be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        n_features : int, default=None\n",
      "            The number of features to use. If None, it will be inferred from the\n",
      "            maximum column index occurring in any of the files.\n",
      "        \n",
      "            This can be set to a higher value than the actual number of features\n",
      "            in any of the input files, but setting it to a lower value will cause\n",
      "            an exception to be raised.\n",
      "        \n",
      "        dtype : numpy data type, default=np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : bool, default=False\n",
      "            Samples may have several labels each (see\n",
      "            https:\/\/www.csie.ntu.edu.tw\/~cjlin\/libsvmtools\/datasets\/multilabel.html)\n",
      "        \n",
      "        zero_based : bool or \"auto\", default=\"auto\"\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python\/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no offset or length is passed.\n",
      "            If offset or length are passed, the \"auto\" mode falls back\n",
      "            to zero_based=True to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : bool, default=False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : int, default=0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : int, default=-1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        [X1, y1, ..., Xn, yn]\n",
      "        where each (Xi, yi) pair is the result from load_svmlight_file(files[i]).\n",
      "        \n",
      "        If query_id is set to True, this will return instead [X1, y1, q1,\n",
      "        ..., Xn, yn, qn] where (Xi, yi, qi) is the result from\n",
      "        load_svmlight_file(files[i])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When fitting a model to a matrix X_train and evaluating it against a\n",
      "        matrix X_test, it is essential that X_train and X_test have the same\n",
      "        number of features (X_train.shape[1] == X_test.shape[1]). This may not\n",
      "        be the case if you load the files individually with load_svmlight_file.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        load_svmlight_file\n",
      "    \n",
      "    load_wine(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the wine dataset (classification).\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        The wine dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class        [59,71,48]\n",
      "        Samples total                  178\n",
      "        Dimensionality                  13\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <wine_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (178, 13)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (178,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "            frame: DataFrame of shape (178, 14)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "        The copy of UCI ML Wine Data Set dataset is downloaded and modified to fit\n",
      "        standard format from:\n",
      "        https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/wine\/wine.data\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 80, and 140, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_wine\n",
      "        >>> data = load_wine()\n",
      "        >>> data.target[[10, 80, 140]]\n",
      "        array([0, 1, 2])\n",
      "        >>> list(data.target_names)\n",
      "        ['class_0', 'class_1', 'class_2']\n",
      "    \n",
      "    make_biclusters(shape, n_clusters, *, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with constant block diagonal structure for\n",
      "        biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : iterable of shape (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : int\n",
      "            The number of biclusters.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, default=10\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, default=100\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : ndarray of shape (n_clusters, X.shape[0])\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : ndarray of shape (n_clusters, X.shape[1])\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Dhillon, I. S. (2001, August). Co-clustering documents and\n",
      "            words using bipartite spectral graph partitioning. In Proceedings\n",
      "            of the seventh ACM SIGKDD international conference on Knowledge\n",
      "            discovery and data mining (pp. 269-274). ACM.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_checkerboard\n",
      "    \n",
      "    make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0, center_box=(-10.0, 10.0), shuffle=True, random_state=None, return_centers=False)\n",
      "        Generate isotropic Gaussian blobs for clustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or array-like, default=100\n",
      "            If int, it is the total number of points equally divided among\n",
      "            clusters.\n",
      "            If array-like, each element of the sequence indicates\n",
      "            the number of samples per cluster.\n",
      "        \n",
      "            .. versionchanged:: v0.20\n",
      "                one can now pass an array-like to the ``n_samples`` parameter\n",
      "        \n",
      "        n_features : int, default=2\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        centers : int or ndarray of shape (n_centers, n_features), default=None\n",
      "            The number of centers to generate, or the fixed center locations.\n",
      "            If n_samples is an int and centers is None, 3 centers are generated.\n",
      "            If n_samples is array-like, centers must be\n",
      "            either None or an array of length equal to the length of n_samples.\n",
      "        \n",
      "        cluster_std : float or array-like of float, default=1.0\n",
      "            The standard deviation of the clusters.\n",
      "        \n",
      "        center_box : tuple of float (min, max), default=(-10.0, 10.0)\n",
      "            The bounding box for each cluster center when centers are\n",
      "            generated at random.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        return_centers : bool, default=False\n",
      "            If True, then return the centers of each cluster\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels for cluster membership of each sample.\n",
      "        \n",
      "        centers : ndarray of shape (n_centers, n_features)\n",
      "            The centers of each cluster. Only returned if\n",
      "            ``return_centers=True``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_blobs\n",
      "        >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      "        >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_classification : A more intricate variant.\n",
      "    \n",
      "    make_checkerboard(shape, n_clusters, *, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with block checkerboard structure for\n",
      "        biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : tuple of shape (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : int or array-like or shape (n_row_clusters, n_column_clusters)\n",
      "            The number of row and column clusters.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, default=10\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, default=100\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : ndarray of shape (n_clusters, X.shape[0])\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : ndarray of shape (n_clusters, X.shape[1])\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Kluger, Y., Basri, R., Chang, J. T., & Gerstein, M. (2003).\n",
      "            Spectral biclustering of microarray data: coclustering genes\n",
      "            and conditions. Genome research, 13(4), 703-716.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_biclusters\n",
      "    \n",
      "    make_circles(n_samples=100, *, shuffle=True, noise=None, random_state=None, factor=0.8)\n",
      "        Make a large circle containing a smaller circle in 2d.\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or tuple of shape (2,), dtype=int, default=100\n",
      "            If int, it is the total number of points generated.\n",
      "            For odd numbers, the inner circle will have one point more than the\n",
      "            outer circle.\n",
      "            If two-element tuple, number of points in outer circle and inner\n",
      "            circle.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Added two-element tuple.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : float, default=None\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        factor : float, default=.8\n",
      "            Scale factor between inner and outer circle in the range `(0, 1)`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 2)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "        Generate a random n-class classification problem.\n",
      "        \n",
      "        This initially creates clusters of points normally distributed (std=1)\n",
      "        about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "        length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "        class. It introduces interdependence between these features and adds\n",
      "        various types of further noise to the data.\n",
      "        \n",
      "        Without shuffling, ``X`` horizontally stacks features in the following\n",
      "        order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "        linear combinations of the informative features, followed by ``n_repeated``\n",
      "        duplicates, drawn randomly with replacement from the informative and\n",
      "        redundant features. The remaining features are filled with random noise.\n",
      "        Thus, without shuffling, all useful features are contained in the columns\n",
      "        ``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=20\n",
      "            The total number of features. These comprise ``n_informative``\n",
      "            informative features, ``n_redundant`` redundant features,\n",
      "            ``n_repeated`` duplicated features and\n",
      "            ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "            drawn at random.\n",
      "        \n",
      "        n_informative : int, default=2\n",
      "            The number of informative features. Each class is composed of a number\n",
      "            of gaussian clusters each located around the vertices of a hypercube\n",
      "            in a subspace of dimension ``n_informative``. For each cluster,\n",
      "            informative features are drawn independently from  N(0, 1) and then\n",
      "            randomly linearly combined within each cluster in order to add\n",
      "            covariance. The clusters are then placed on the vertices of the\n",
      "            hypercube.\n",
      "        \n",
      "        n_redundant : int, default=2\n",
      "            The number of redundant features. These features are generated as\n",
      "            random linear combinations of the informative features.\n",
      "        \n",
      "        n_repeated : int, default=0\n",
      "            The number of duplicated features, drawn randomly from the informative\n",
      "            and the redundant features.\n",
      "        \n",
      "        n_classes : int, default=2\n",
      "            The number of classes (or labels) of the classification problem.\n",
      "        \n",
      "        n_clusters_per_class : int, default=2\n",
      "            The number of clusters per class.\n",
      "        \n",
      "        weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "            The proportions of samples assigned to each class. If None, then\n",
      "            classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "            then the last class weight is automatically inferred.\n",
      "            More than ``n_samples`` samples may be returned if the sum of\n",
      "            ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "            not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "        \n",
      "        flip_y : float, default=0.01\n",
      "            The fraction of samples whose class is assigned randomly. Larger\n",
      "            values introduce noise in the labels and make the classification\n",
      "            task harder. Note that the default setting flip_y > 0 might lead\n",
      "            to less than ``n_classes`` in y in some cases.\n",
      "        \n",
      "        class_sep : float, default=1.0\n",
      "            The factor multiplying the hypercube size.  Larger values spread\n",
      "            out the clusters\/classes and make the classification task easier.\n",
      "        \n",
      "        hypercube : bool, default=True\n",
      "            If True, the clusters are put on the vertices of a hypercube. If\n",
      "            False, the clusters are put on the vertices of a random polytope.\n",
      "        \n",
      "        shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "            Shift features by the specified value. If None, then features\n",
      "            are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "        \n",
      "        scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "            Multiply features by the specified value. If None, then features\n",
      "            are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "            happens after shifting.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels for class membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "        the \"Madelon\" dataset.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "               selection benchmark\", 2003.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_blobs : Simplified variant.\n",
      "        make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "    \n",
      "    make_friedman1(n_samples=100, n_features=10, *, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #1\" regression problem.\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are independent features uniformly distributed on the interval\n",
      "        [0, 1]. The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = 10 * sin(pi * X[:, 0] * X[:, 1]) + 20 * (X[:, 2] - 0.5) ** 2 + 10 * X[:, 3] + 5 * X[:, 4] + noise * N(0, 1).\n",
      "        \n",
      "        Out of the `n_features` features, only 5 are actually used to compute\n",
      "        `y`. The remaining features are independent of `y`.\n",
      "        \n",
      "        The number of features has to be >= 5.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=10\n",
      "            The number of features. Should be at least 5.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman2(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #2\" regression problem.\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = (X[:, 0] ** 2 + (X[:, 1] * X[:, 2]  - 1 \/ (X[:, 1] * X[:, 3])) ** 2) ** 0.5 + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 4)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman3(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #3\" regression problem.\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = arctan((X[:, 1] * X[:, 2] - 1 \/ (X[:, 1] * X[:, 3])) \/ X[:, 0]) + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 4)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_gaussian_quantiles(*, mean=None, cov=1.0, n_samples=100, n_features=2, n_classes=3, shuffle=True, random_state=None)\n",
      "        Generate isotropic Gaussian and label samples by quantile.\n",
      "        \n",
      "        This classification dataset is constructed by taking a multi-dimensional\n",
      "        standard normal distribution and defining classes separated by nested\n",
      "        concentric multi-dimensional spheres such that roughly equal numbers of\n",
      "        samples are in each class (quantiles of the :math:`\\chi^2` distribution).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : ndarray of shape (n_features,), default=None\n",
      "            The mean of the multi-dimensional normal distribution.\n",
      "            If None then use the origin (0, 0, ...).\n",
      "        \n",
      "        cov : float, default=1.0\n",
      "            The covariance matrix will be this value times the unit matrix. This\n",
      "            dataset only produces symmetric normal distributions.\n",
      "        \n",
      "        n_samples : int, default=100\n",
      "            The total number of points equally divided among classes.\n",
      "        \n",
      "        n_features : int, default=2\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        n_classes : int, default=3\n",
      "            The number of classes\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels for quantile membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The dataset is from Zhu et al [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class AdaBoost\", 2009.\n",
      "    \n",
      "    make_hastie_10_2(n_samples=12000, *, random_state=None)\n",
      "        Generates data for binary classification used in\n",
      "        Hastie et al. 2009, Example 10.2.\n",
      "        \n",
      "        The ten features are standard independent Gaussian and\n",
      "        the target ``y`` is defined by::\n",
      "        \n",
      "          y[i] = 1 if np.sum(X[i] ** 2) > 9.34 else -1\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=12000\n",
      "            The number of samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 10)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical\n",
      "               Learning Ed. 2\", Springer, 2009.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_gaussian_quantiles : A generalization of this dataset approach.\n",
      "    \n",
      "    make_low_rank_matrix(n_samples=100, n_features=100, *, effective_rank=10, tail_strength=0.5, random_state=None)\n",
      "        Generate a mostly low rank matrix with bell-shaped singular values.\n",
      "        \n",
      "        Most of the variance can be explained by a bell-shaped curve of width\n",
      "        effective_rank: the low rank part of the singular values profile is::\n",
      "        \n",
      "            (1 - tail_strength) * exp(-1.0 * (i \/ effective_rank) ** 2)\n",
      "        \n",
      "        The remaining singular values' tail is fat, decreasing as::\n",
      "        \n",
      "            tail_strength * exp(-0.1 * i \/ effective_rank).\n",
      "        \n",
      "        The low rank part of the profile can be considered the structured\n",
      "        signal part of the data while the tail can be considered the noisy\n",
      "        part of the data that cannot be summarized by a low number of linear\n",
      "        components (singular vectors).\n",
      "        \n",
      "        This kind of singular profiles is often seen in practice, for instance:\n",
      "         - gray level pictures of faces\n",
      "         - TF-IDF vectors of text documents crawled from the web\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=100\n",
      "            The number of features.\n",
      "        \n",
      "        effective_rank : int, default=10\n",
      "            The approximate number of singular vectors required to explain most of\n",
      "            the data by linear combinations.\n",
      "        \n",
      "        tail_strength : float, default=0.5\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile. The value should be between 0 and 1.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The matrix.\n",
      "    \n",
      "    make_moons(n_samples=100, *, shuffle=True, noise=None, random_state=None)\n",
      "        Make two interleaving half circles.\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms. Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or tuple of shape (2,), dtype=int, default=100\n",
      "            If int, the total number of points generated.\n",
      "            If two-element tuple, number of points in each of two moons.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Added two-element tuple.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : float, default=None\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 2)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_multilabel_classification(n_samples=100, n_features=20, *, n_classes=5, n_labels=2, length=50, allow_unlabeled=True, sparse=False, return_indicator='dense', return_distributions=False, random_state=None)\n",
      "        Generate a random multilabel classification problem.\n",
      "        \n",
      "        For each sample, the generative process is:\n",
      "            - pick the number of labels: n ~ Poisson(n_labels)\n",
      "            - n times, choose a class c: c ~ Multinomial(theta)\n",
      "            - pick the document length: k ~ Poisson(length)\n",
      "            - k times, choose a word: w ~ Multinomial(theta_c)\n",
      "        \n",
      "        In the above process, rejection sampling is used to make sure that\n",
      "        n is never zero or more than `n_classes`, and that the document length\n",
      "        is never zero. Likewise, we reject classes which have already been chosen.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=20\n",
      "            The total number of features.\n",
      "        \n",
      "        n_classes : int, default=5\n",
      "            The number of classes of the classification problem.\n",
      "        \n",
      "        n_labels : int, default=2\n",
      "            The average number of labels per instance. More precisely, the number\n",
      "            of labels per sample is drawn from a Poisson distribution with\n",
      "            ``n_labels`` as its expected value, but samples are bounded (using\n",
      "            rejection sampling) by ``n_classes``, and must be nonzero if\n",
      "            ``allow_unlabeled`` is False.\n",
      "        \n",
      "        length : int, default=50\n",
      "            The sum of the features (number of words if documents) is drawn from\n",
      "            a Poisson distribution with this expected value.\n",
      "        \n",
      "        allow_unlabeled : bool, default=True\n",
      "            If ``True``, some instances might not belong to any class.\n",
      "        \n",
      "        sparse : bool, default=False\n",
      "            If ``True``, return a sparse feature matrix\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter to allow *sparse* output.\n",
      "        \n",
      "        return_indicator : {'dense', 'sparse'} or False, default='dense'\n",
      "            If ``'dense'`` return ``Y`` in the dense binary indicator format. If\n",
      "            ``'sparse'`` return ``Y`` in the sparse binary indicator format.\n",
      "            ``False`` returns a list of lists of labels.\n",
      "        \n",
      "        return_distributions : bool, default=False\n",
      "            If ``True``, return the prior class probability and conditional\n",
      "            probabilities of features given classes, from which the data was\n",
      "            drawn.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "            The label sets. Sparse matrix should be of CSR format.\n",
      "        \n",
      "        p_c : ndarray of shape (n_classes,)\n",
      "            The probability of each class being drawn. Only returned if\n",
      "            ``return_distributions=True``.\n",
      "        \n",
      "        p_w_c : ndarray of shape (n_features, n_classes)\n",
      "            The probability of each feature being drawn given each class.\n",
      "            Only returned if ``return_distributions=True``.\n",
      "    \n",
      "    make_regression(n_samples=100, n_features=100, *, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)\n",
      "        Generate a random regression problem.\n",
      "        \n",
      "        The input set can either be well conditioned (by default) or have a low\n",
      "        rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
      "        more details.\n",
      "        \n",
      "        The output is generated by applying a (potentially biased) random linear\n",
      "        regression model with `n_informative` nonzero regressors to the previously\n",
      "        generated input and some gaussian centered noise with some adjustable\n",
      "        scale.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=100\n",
      "            The number of features.\n",
      "        \n",
      "        n_informative : int, default=10\n",
      "            The number of informative features, i.e., the number of features used\n",
      "            to build the linear model used to generate the output.\n",
      "        \n",
      "        n_targets : int, default=1\n",
      "            The number of regression targets, i.e., the dimension of the y output\n",
      "            vector associated with a sample. By default, the output is a scalar.\n",
      "        \n",
      "        bias : float, default=0.0\n",
      "            The bias term in the underlying linear model.\n",
      "        \n",
      "        effective_rank : int, default=None\n",
      "            if not None:\n",
      "                The approximate number of singular vectors required to explain most\n",
      "                of the input data by linear combinations. Using this kind of\n",
      "                singular spectrum in the input allows the generator to reproduce\n",
      "                the correlations often observed in practice.\n",
      "            if None:\n",
      "                The input set is well conditioned, centered and gaussian with\n",
      "                unit variance.\n",
      "        \n",
      "        tail_strength : float, default=0.5\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile if `effective_rank` is not None. When a float, it should be\n",
      "            between 0 and 1.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        coef : bool, default=False\n",
      "            If True, the coefficients of the underlying linear model are returned.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "            The output values.\n",
      "        \n",
      "        coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
      "            The coefficient of the underlying linear model. It is returned only if\n",
      "            coef is True.\n",
      "    \n",
      "    make_s_curve(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate an S curve dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 3)\n",
      "            The points.\n",
      "        \n",
      "        t : ndarray of shape (n_samples,)\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "    \n",
      "    make_sparse_coded_signal(n_samples, *, n_components, n_features, n_nonzero_coefs, random_state=None)\n",
      "        Generate a signal as a sparse combination of dictionary elements.\n",
      "        \n",
      "        Returns a matrix Y = DX, such as D is (n_features, n_components),\n",
      "        X is (n_components, n_samples) and each column of X has exactly\n",
      "        n_nonzero_coefs non-zero elements.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int\n",
      "            Number of samples to generate\n",
      "        \n",
      "        n_components : int\n",
      "            Number of components in the dictionary\n",
      "        \n",
      "        n_features : int\n",
      "            Number of features of the dataset to generate\n",
      "        \n",
      "        n_nonzero_coefs : int\n",
      "            Number of active (non-zero) coefficients in each sample\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : ndarray of shape (n_features, n_samples)\n",
      "            The encoded signal (Y).\n",
      "        \n",
      "        dictionary : ndarray of shape (n_features, n_components)\n",
      "            The dictionary with normalized components (D).\n",
      "        \n",
      "        code : ndarray of shape (n_components, n_samples)\n",
      "            The sparse code such that each column of this matrix has exactly\n",
      "            n_nonzero_coefs non-zero items (X).\n",
      "    \n",
      "    make_sparse_spd_matrix(dim=1, *, alpha=0.95, norm_diag=False, smallest_coef=0.1, largest_coef=0.9, random_state=None)\n",
      "        Generate a sparse symmetric definite positive matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dim : int, default=1\n",
      "            The size of the random matrix to generate.\n",
      "        \n",
      "        alpha : float, default=0.95\n",
      "            The probability that a coefficient is zero (see notes). Larger values\n",
      "            enforce more sparsity. The value should be in the range 0 and 1.\n",
      "        \n",
      "        norm_diag : bool, default=False\n",
      "            Whether to normalize the output matrix to make the leading diagonal\n",
      "            elements all 1\n",
      "        \n",
      "        smallest_coef : float, default=0.1\n",
      "            The value of the smallest coefficient between 0 and 1.\n",
      "        \n",
      "        largest_coef : float, default=0.9\n",
      "            The value of the largest coefficient between 0 and 1.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        prec : sparse matrix of shape (dim, dim)\n",
      "            The generated matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sparsity is actually imposed on the cholesky factor of the matrix.\n",
      "        Thus alpha does not translate directly into the filling fraction of\n",
      "        the matrix itself.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_spd_matrix\n",
      "    \n",
      "    make_sparse_uncorrelated(n_samples=100, n_features=10, *, random_state=None)\n",
      "        Generate a random regression problem with sparse uncorrelated design.\n",
      "        \n",
      "        This dataset is described in Celeux et al [1]. as::\n",
      "        \n",
      "            X ~ N(0, 1)\n",
      "            y(X) = X[:, 0] + 2 * X[:, 1] - 2 * X[:, 2] - 1.5 * X[:, 3]\n",
      "        \n",
      "        Only the first 4 features are informative. The remaining features are\n",
      "        useless.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=10\n",
      "            The number of features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert,\n",
      "               \"Regularization in regression: comparing Bayesian and frequentist\n",
      "               methods in a poorly informative situation\", 2009.\n",
      "    \n",
      "    make_spd_matrix(n_dim, *, random_state=None)\n",
      "        Generate a random symmetric, positive-definite matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_dim : int\n",
      "            The matrix dimension.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_dim, n_dim)\n",
      "            The random symmetric, positive-definite matrix.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_sparse_spd_matrix\n",
      "    \n",
      "    make_swiss_roll(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate a swiss roll dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 3)\n",
      "            The points.\n",
      "        \n",
      "        t : ndarray of shape (n_samples,)\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is from Marsland [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] S. Marsland, \"Machine Learning: An Algorithmic Perspective\",\n",
      "               Chapter 10, 2009.\n",
      "               http:\/\/seat.massey.ac.nz\/personal\/s.r.marsland\/Code\/10\/lle.py\n",
      "\n",
      "DATA\n",
      "    __all__ = ['clear_data_home', 'dump_svmlight_file', 'fetch_20newsgroup...\n",
      "\n",
      "FILE\n",
      "    \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/datasets\/__init__.py\n",
      "\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"CxQutXVfjGGi8iylahe31m",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "iris = datasets.load_iris()\n",
    "iris"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\i.betlei\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"xkzn8BHTyRCfkp6F3WpU7n",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"7NcGCn8XbDjxoHLo2hAdtC"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 1. Готові набори"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"tPFJTa0M1tr9WVwIDPFpW0",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"olREfQzRwINS0Qt5wnBYOv"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"GACTMDp5PJ8cLhTo8MPmdy",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"mvbajg3S3dAInNJqFvCQkb"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "features = boston.data\n",
    "target = boston.target\n",
    "feature_names = boston.feature_names"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"nyIwID68qqdkBZ7JZBkPGT",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"UeUerVf3uPa85toOFpl467"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print(boston.DESCR)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric\/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/housing\/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"AtiU59ofY825uKogQxOczV",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"HjMEGJiyhOKPFaz0C9gXnX"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "- Для задачі регресії - load_boston\n",
    "- Для задачі класифікації - load_iris\n",
    "- Для класифікації зорбражень - load_digits"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"GSLw7SIiNpmpyG671BRysJ",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"yn4amehUpbL9cJdr14RoLs"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "features, target, coefficients = make_regression(n_samples = 100,\n",
    "                                                 n_features = 3,\n",
    "                                                 n_informative = 3,\n",
    "                                                 n_targets = 1,\n",
    "                                                 noise = 0.0,\n",
    "                                                 coef = True,\n",
    "                                                 random_state = 1)\n",
    "\n",
    "\n",
    "print('Target \\n', features[:5])\n",
    "print('Features \\n', target[:5])"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Target \n",
      " [[ 1.29322588 -0.61736206 -0.11044703]\n",
      " [-2.793085    0.36633201  1.93752881]\n",
      " [ 0.80186103 -0.18656977  0.0465673 ]\n",
      " [ 0.12910158  0.50274088  1.6169496 ]\n",
      " [-0.69166075 -0.6871727  -0.39675353]]\n",
      "Features \n",
      " [ -10.37865986   25.5124503    19.67705609  149.50205427 -121.65210879]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Ze1m3GR7AbwGe7015APFHT",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"SsEDiAvtWiYKvxs5yUBuD3"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "features, target = make_blobs(n_samples = 100,\n",
    "                              n_features = 2,\n",
    "                              centers = 3,\n",
    "                              cluster_std = 0.5,\n",
    "                              shuffle = True,\n",
    "                              random_state = 1)\n",
    "\n",
    "print('Target\\n', features[:3])\n",
    "print('Features \\n', target[:3])"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Матрица признаков\n",
      " [[ -1.22685609   3.25572052]\n",
      " [ -9.57463218  -4.38310652]\n",
      " [-10.71976941  -4.20558148]]\n",
      "Вектор целей\n",
      " [0 1 1]\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"gcBDSk3ZgCP2kUS5rax1sb",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"EUsqaMRxPKTNoPK4Z0FSGM"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(features[:,0], features[:,1], c=target)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "image\/png":[
       "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\n"
      ]
     },
     "metadata":{
      "image\/png":{
       
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"kTMl9Ti9DrJQpNptzkElLR",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"hPrUPpePGXF3HqWxvJawN0"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 2. МінМакс шаклювання"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"7w5KWcSIV36rScEgT432Qa",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"SY3Yt9HslwXIOLHMcAWT4a"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "MinMaxScaler - це метод масштабування, який шкалює всі ознаки в діапазоні від 0 до 1. Це корисно, коли дані мають різні діапазони значень і потребують нормалізації для подальшої обробки."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"DpMjjzPv4B9oLAX5Tht4QA",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"6NLGrxrFkEhkNZLpWCWnf7",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"oNV9fkpYqO5cIktDcW5Acm"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 3. Стандартизація"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"QCucNcyLuK8lbqDqYiNI8Y",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"GGhlVTet57KhJG991pW6cs"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "StandardScaler є одним з найпоширеніших методів масштабування даних в машинному навчанні. Цей метод масштабує кожен ознаку (або стовпець) вхідних даних таким чином, щоб вона мала середнє значення 0 та стандартне відхилення 1.\n",
    "\n",
    "Для кожної ознаки x вхідних даних формула для масштабування виглядає наступним чином:\n",
    "\n",
    "z = (x - mean) \/ std\n",
    "\n",
    "де mean - середнє значення ознаки, а std - стандартне відхилення ознаки.\n",
    "\n",
    "Ця формула знаходить зміщення (або різницю) між кожним значенням ознаки та її середнім значенням, а потім ділить це зміщення на стандартне відхилення, щоб отримати значення з новим масштабом.\n",
    "\n",
    "Це масштабування даних дозволяє уникнути проблем з впливом великих значень на модель машинного навчання, які можуть зробити менш вагомими інші ознаки, які мають менші значення. Також це допомагає зробити функціонування алгоритмів машинного навчання більш стабільним та швидким."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ieWOdzC7I6c6FdqdDBCEYN",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = np.array([[-1000.1],\n",
    "              [-200.2],\n",
    "              [500.5],\n",
    "              [600.6],\n",
    "              [9000.9]])\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "standardized"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"hOioC7Ync0BC7Lce9PLxKl",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"REhB7S4zAMOi6oBqa6LnZf"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print(\"mean:\", round(standardized.mean()))\n",
    "print(\"std\", standardized.std())"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "mean: 0\n",
      "std 1.0\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"JcWqZhYtJdlCvixw9ZXMjS",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"FPD8vbZod8W9T3CerwBBj3"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "RobustScaler є методом масштабування даних, який також дозволяє уникнути впливу великих значень, але він використовує іншу формулу порівняно з StandardScaler.\n",
    "\n",
    "Для кожної ознаки x вхідних даних формула для масштабування виглядає наступним чином:\n",
    "\n",
    "x_scaled = (x - Q2) \/ (Q3 - Q1)\n",
    "\n",
    "де Q2 - медіана ознаки, Q1 - 25-й персентиль, Q3 - 75-й персентиль.\n",
    "\n",
    "Ця формула використовує медіану та квартилі, замість середнього значення та стандартного відхилення, щоб масштабувати дані. Це робить метод більш стійким до викидів (або outliers), оскільки він використовує медіану, яка не піддається впливу викидів.\n",
    "\n",
    "RobustScaler може бути корисним методом масштабування даних, коли вхідні дані містять викиди, або коли потрібно зробити алгоритми машинного навчання більш стійкими до викидів. Однак, як і в будь-якому методі масштабування даних, важливо добре зрозуміти дані та їх характеристики, щоб вибрати найкращий метод масштабування для конкретної задачі."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"NugNzxkA5vVyKMxwxuxcQf",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "robust_scaler.fit_transform(x)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"PT3MvEdOiPaqrCpTN71VIv",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"K7oU9v0DgoKlofwFstnNlT"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 4. Нормалізація"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"USORNDAjOpzyRVMS3AixJV",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"fDG8Pngiwdq50OSW9P84Iy"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Normalizer - це метод масштабування даних, що перетворює кожний зразок вектора функцій на вектор одиничної довжини. Це означає, що кожен зразок буде знаходитися на сфері одиничного радіусу, де його Євклідова норма (довжина вектора) дорівнює 1.\n",
    "\n",
    "Це досягається шляхом знаходження норми кожного зразка (довжини вектора) і поділом кожного елемента вектора на цю норму. Якщо вихідні дані відображають довжину або кількість, то таке масштабування може бути корисним для забезпечення однакового впливу на кожен зразок.\n",
    "\n",
    "Таким чином, масштабування Normalizer дозволяє зменшити вплив масштабування на довжину зразка та покращити нормалізацію даних. Використання Normalizer є корисним, коли кількість та довжина вектора має значення в аналізі даних."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"A2Vz2jWBNuLmqsNyNWQt8u",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "features = np.array([[0.5, 0.5],\n",
    "                     [1.1, 3.4],\n",
    "                     [1.5, 20.2],\n",
    "                     [1.63, 34.4],\n",
    "                     [10.9, 3.3]])\n",
    "\n",
    "\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "\n",
    "\n",
    "normalizer.transform(features)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"vzg5dLKME10gf1CKIfF69M",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"XOBw9j97y2ex5jjsQjHPUL"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "features_l2_norm = Normalizer(norm=\"l2\").transform(features)\n",
    "\n",
    "\n",
    "features_l2_norm"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"1BHPciKE1YtCLzi3PcZOLl",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"JMiRwqxAhLWmAQW6AjD0fM"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "\n",
    "\n",
    "features_l1_norm"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"VqvkQpAgdAg1u3lreNz1J6",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"DBZ2pYhdIJbUDZ0GhOwpcE"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 5. Трансформація"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"gB9VAo6T0IRgJLHjcAdudT",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"n8J3BJ6WrYeME72ApuNrxe"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "features = np.array([[2, 3],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "\n",
    "\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "\n",
    "ten_transformer.transform(features)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"aCMSu4uTU8XPLrY82OzIX3",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"Fn6kpvdITj1kNopUp5uy0J"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(features, columns=[\"признак_1\", \"признак_2\"])\n",
    "\n",
    "\n",
    "df.apply(add_ten)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>признак_1<\/th>\n",
       "      <th>признак_2<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>12<\/td>\n",
       "      <td>13<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>12<\/td>\n",
       "      <td>13<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>12<\/td>\n",
       "      <td>13<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "   признак_1  признак_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"aALgSv8Se7409zULFnbSN3",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"upRo9wYXFypR1yZVibux4Z"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 6. Робота із викидами"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"RYIJRtuk85A8ClwQNOwk4m",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"twIpR7aVYHVZg9ljAZNFw8"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Робота з викидами (outliers) є важливою складовою аналізу даних. Викиди - це значення, що відрізняється значно від інших значень у наборі даних та може викликати помилкові результати під час аналізу даних."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"fuiGmMnAaToTxgakLjrneC",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Elliptic Envelope є методом виявлення аномалій (outlier detection) в машинному навчанні. Цей метод використовує гаусівський розподіл даних та оцінює еліптичну область, що містить більшість даних, відносно якої можна визначити наявність аномальних даних."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"NCqYanBgxtSCCJc63DeOJy",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    " \n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                         n_features = 2,\n",
    "                         centers = 1,\n",
    "                         random_state = 1)\n",
    "\n",
    "\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "\n",
    "\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "\n",
    "\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "\n",
    "outlier_detector.predict(features)"
   ],
   "execution_count":5,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"34CoKwgK5xMGCWGJbN6RUf",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"V4F7n6y6OI5AFfoVUTQ4ba"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "features"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[ 1.00000000e+04,  1.00000000e+04],\n",
       "       [-2.76017908e+00,  5.55121358e+00],\n",
       "       [-1.61734616e+00,  4.98930508e+00],\n",
       "       [-5.25790464e-01,  3.30659860e+00],\n",
       "       [ 8.52518583e-02,  3.64528297e+00],\n",
       "       [-7.94152277e-01,  2.10495117e+00],\n",
       "       [-1.34052081e+00,  4.15711949e+00],\n",
       "       [-1.98197711e+00,  4.02243551e+00],\n",
       "       [-2.18773166e+00,  3.33352125e+00],\n",
       "       [-1.97451969e-01,  2.34634916e+00]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"V2J8bgat5jY7hEZjCENYGc",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"xmw2rrQOub1Rq7137sFmp4"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "feature = features[:]\n",
    "\n",
    "\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "\n",
    "\n",
    "indicies_of_outliers(feature)"
   ],
   "execution_count":2,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "(array([0, 0]), array([0, 1]))"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"DfOvZ8jD8ztDwnGzlbtHuF",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"DUUbzxyxa1pSbgmNNGjDvj"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Один з найчастіших випадків, коли логарифмування може бути корисним, - це коли даний набір даних має складну або нелінійну залежність між змінними, але ми хочемо побудувати лінійну регресійну модель. Логарифмування може допомогти \"згладити\" дані та зменшити вплив складних залежностей, дозволяючи лінійній моделі краще апроксимувати дані.\n",
    "\n",
    "Наприклад, при аналізі цін на нерухомість, можна логарифмувати ціни, якщо вони ростуть експоненційно. Після логарифмування виходить, що кожне одиниця зміни логарифму відповідає певному відсотку зміни оригінальної ціни. Це може зробити модель більш інтерпретованою та легшою для використання.\n",
    "\n",
    "Крім того, логарифмування може допомогти зменшити вплив великих відхилень в даних, таких як викиди. Логарифмування зменшує різницю між великими та малими значеннями, тому збільшує чутливість моделі до менших значень, зменшуючи вплив великих значень."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"tQNvVE9e2i45L79be0ttmO",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "\n",
    " \n",
    "houses = pd.DataFrame()\n",
    "houses['Цена'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Ванные'] = [2, 3.5, 2, 116]\n",
    "houses['Кв_футы'] = [1500, 2500, 1500, 48000]\n",
    "\n",
    "\n",
    "houses[houses['Ванные'] < 20]"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>Цена<\/th>\n",
       "      <th>Ванные<\/th>\n",
       "      <th>Кв_футы<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>534433<\/td>\n",
       "      <td>2.0<\/td>\n",
       "      <td>1500<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>392333<\/td>\n",
       "      <td>3.5<\/td>\n",
       "      <td>2500<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>293222<\/td>\n",
       "      <td>2.0<\/td>\n",
       "      <td>1500<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "     Цена  Ванные  Кв_футы\n",
       "0  534433     2.0     1500\n",
       "1  392333     3.5     2500\n",
       "2  293222     2.0     1500"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"iT60w1q5vpVBy29fqdFw6Z",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"vfhq54ZWSuw5hoCLDBnClO"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "houses[\"Выброс\"] = np.where(houses[\"Ванные\"] < 20, 0, 1)\n",
    "\n",
    "houses"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>Цена<\/th>\n",
       "      <th>Ванные<\/th>\n",
       "      <th>Кв_футы<\/th>\n",
       "      <th>Выброс<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>534433<\/td>\n",
       "      <td>2.0<\/td>\n",
       "      <td>1500<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>392333<\/td>\n",
       "      <td>3.5<\/td>\n",
       "      <td>2500<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>293222<\/td>\n",
       "      <td>2.0<\/td>\n",
       "      <td>1500<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>4322032<\/td>\n",
       "      <td>116.0<\/td>\n",
       "      <td>48000<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "      Цена  Ванные  Кв_футы  Выброс\n",
       "0   534433     2.0     1500       0\n",
       "1   392333     3.5     2500       0\n",
       "2   293222     2.0     1500       0\n",
       "3  4322032   116.0    48000       1"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"4dCOgwiCcoyVqvHZh0cukX",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"zxhwLumwWgVFHALSND1wIb"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "houses[\"Логарифм_кв_футов\"] = [np.log(x) for x in houses[\"Кв_футы\"]]\n",
    "\n",
    "\n",
    "houses"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>Цена<\/th>\n",
       "      <th>Ванные<\/th>\n",
       "      <th>Кв_футы<\/th>\n",
       "      <th>Выброс<\/th>\n",
       "      <th>Логарифм_кв_футов<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>534433<\/td>\n",
       "      <td>2.0<\/td>\n",
       "      <td>1500<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>7.313220<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>392333<\/td>\n",
       "      <td>3.5<\/td>\n",
       "      <td>2500<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>7.824046<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>293222<\/td>\n",
       "      <td>2.0<\/td>\n",
       "      <td>1500<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>7.313220<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>4322032<\/td>\n",
       "      <td>116.0<\/td>\n",
       "      <td>48000<\/td>\n",
       "      <td>1<\/td>\n",
       "      <td>10.778956<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "      Цена  Ванные  Кв_футы  Выброс  Логарифм_кв_футов\n",
       "0   534433     2.0     1500       0           7.313220\n",
       "1   392333     3.5     2500       0           7.824046\n",
       "2   293222     2.0     1500       0           7.313220\n",
       "3  4322032   116.0    48000       1          10.778956"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"CBaH5Y7rx3NyrFdrBgs5Dc",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"erU4CVJZ0eXoHj2v8GZVfD"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 7. Бінарізація"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"0MPIwWKjPaXTMffOOopWYz",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"BiXkzeIDM5z5EUSXo7c5cY"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "age = np.array([[6],\n",
    "                [12],\n",
    "                [20],\n",
    "                [36],\n",
    "                [65]])\n",
    "\n",
    "binarizer = Binarizer(threshold=18)\n",
    "\n",
    "binarizer.fit_transform(age)"
   ],
   "execution_count":18,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"JAFf9a7qKFShkJCaBNdA9j",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"LLM6sPiBcTRDr6ny06PfSY"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "np.digitize(age, bins=[20,30,64])"
   ],
   "execution_count":19,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"ERRB8Z9ICOba2dZmi6eu36",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"WAMAf8ni6h64dlMnknBDPO"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 8. Робота з пропущиними значеннями"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"8J7DwKaVOoTwpUVTVRgQnB",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"a2v0KyPIYUUFNAvUlopPJ6"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "\n",
    "features = np.array([[1.1, 11.1],\n",
    "                     [2.2, 22.2],\n",
    "                     [3.3, 33.3],\n",
    "                     [4.4, 44.4],\n",
    "                     [np.nan, 55]])\n",
    "\n",
    "features[~np.isnan(features).any(axis=1)]"
   ],
   "execution_count":22,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<pre>array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])<\/pre>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"XqaWAXgyfzQAztfBZLdw0v",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"17XG2nBtxsF9kgq9LiMa8b"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#????np.isnan(features).any(axis=1)"
   ],
   "execution_count":30,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"7q078REATT1cMOAOjFrXpg",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "MCAR (Missing Completely At Random) означає, що відсутність даних повністю випадкова, тобто ймовірність відсутності даних не залежить від жодних інших факторів. Наприклад, якщо в опитуванні відповідачі мали можливість відповісти на всі запитання, але деякі не відповіли, то відсутність даних є MCAR.\n",
    "\n",
    "MAR (Missing At Random) означає, що відсутність даних залежить від інших змінних в досліді, але не залежить від самої відсутності даних. Наприклад, якщо в опитуванні відповідачі з вищою освітою частіше відповідали на запитання, ніж відповідачі з нижчою освітою, то відсутність даних є MAR.\n",
    "\n",
    "MNAR (Missing Not At Random) означає, що відсутність даних залежить від самої відсутності даних, тобто вона є систематичною і залежить від якихось невідомих чинників. Наприклад, якщо в опитуванні відповідачі, які не відповіли на запитання про заробітну плату, отримують вищу зарплату, ніж ті, що відповіли, то відсутність даних є MNAR. В такому випадку може бути важко коректно оцінити результати дослідження."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"RSw6kcztomSEKcma3FrIg7",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"5Rg0ikGmtQBWlmN5FVNPQp"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame(features, columns=[\"признак_1\", \"признак_2\"])\n",
    "\n",
    "dataframe.dropna()"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>признак_1<\/th>\n",
       "      <th>признак_2<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>1.1<\/td>\n",
       "      <td>11.1<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>2.2<\/td>\n",
       "      <td>22.2<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>3.3<\/td>\n",
       "      <td>33.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>4.4<\/td>\n",
       "      <td>44.4<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "   признак_1  признак_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"LfYpMLCkaEUvrD48m6TNyi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"cELYYnvVYzdqSyHAEwJzeD"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute  import SimpleImputer\n",
    "\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                         n_features = 2,\n",
    "                         random_state = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "\n",
    "\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "\n",
    "features_mean_imputed = mean_imputer.fit_transform(features)\n",
    "\n",
    "print(\"Справжне значення:\", true_value)\n",
    "print(\"Імпутоване значення:\", features_mean_imputed[0,0])"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Справжне значення: 0.8730186113995938\n",
      "Імпутоване значення: -3.058372724614996\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Pq4e4o3EsIBWoJnTM991KL",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"poeYcuz7rAk39jVGGKGM1b"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### 9. Кодування даних"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"mGQ8UcgAthN6LtLIJuWFYo",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"m0r3yLrIISxbZekwHocAnR"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "feature = np.array([[\"Texas\"],\n",
    "                    [\"California\"],\n",
    "                    [\"Texas\"],\n",
    "                    [\"Delaware\"],\n",
    "                    [\"Texas\"]])\n",
    "\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "one_hot.fit_transform(feature)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Vh30sah7Bmhw6sv2ZXopL2",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"6VkCZTWvUgeTtG716BikAN"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "\n",
    "pd.get_dummies(feature[:,0])"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>California<\/th>\n",
       "      <th>Delaware<\/th>\n",
       "      <th>Texas<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>0<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>1<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>0<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>0<\/td>\n",
       "      <td>1<\/td>\n",
       "      <td>0<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>0<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>1<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"xaAW0OuDxEDXWrWoHr585k",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"bORNScKZHUcUz3D0l0x9nr"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame({\"оценка\": [\"низкая\", \"низкая\", \n",
    "                                     \"средняя\", \"средняя\", \"высокая\"]})\n",
    "scale_mapper = {\"низкая\":1,\n",
    "                \"средняя\":2,\n",
    "                \"высокая\":3}\n",
    "\n",
    "dataframe[\"оценка\"].replace(scale_mapper)"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: оценка, dtype: int64"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Ap2lOYbErxKSLbAxLVlA7G",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"aqxWlRTnxYHvXDNABhvWkd"
     }
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    "zr2ZKP7xQEj7U7vvXEplLV",
    "7NcGCn8XbDjxoHLo2hAdtC",
    "bIQzbRJAaTo4JzDua9h3DL",
    "zMtgmgynRWskjFLfsesPx8",
    "T41vIcjDKj0M2YMCtpBpiO",
    "QT38DHsvsxwB3sARx5FjTw",
    "Ikkvh2ykXqCEzwYVJCJ3ZD",
    "TQdiwQ4YDxKrNfLEgQkejw",
    "cX0YLxxenfGMCVlb5Uu75e",
    "yPaCNorDfRDJmkR7zUnYxI",
    "TL70vRQB7BDdGO9e6ueDqZ",
    "0sJXgPZgbMhG8mcMcxsF2s",
    "knLuZhhFT00knM8m4o0JiL",
    "olREfQzRwINS0Qt5wnBYOv",
    "mvbajg3S3dAInNJqFvCQkb",
    "UeUerVf3uPa85toOFpl467",
    "HjMEGJiyhOKPFaz0C9gXnX",
    "yn4amehUpbL9cJdr14RoLs",
    "SsEDiAvtWiYKvxs5yUBuD3",
    "EUsqaMRxPKTNoPK4Z0FSGM",
    "hPrUPpePGXF3HqWxvJawN0",
    "SY3Yt9HslwXIOLHMcAWT4a",
    "oNV9fkpYqO5cIktDcW5Acm",
    "GGhlVTet57KhJG991pW6cs",
    "REhB7S4zAMOi6oBqa6LnZf",
    "FPD8vbZod8W9T3CerwBBj3",
    "K7oU9v0DgoKlofwFstnNlT",
    "fDG8Pngiwdq50OSW9P84Iy",
    "XOBw9j97y2ex5jjsQjHPUL",
    "JMiRwqxAhLWmAQW6AjD0fM",
    "DBZ2pYhdIJbUDZ0GhOwpcE",
    "n8J3BJ6WrYeME72ApuNrxe",
    "Fn6kpvdITj1kNopUp5uy0J",
    "upRo9wYXFypR1yZVibux4Z",
    "twIpR7aVYHVZg9ljAZNFw8",
    "V4F7n6y6OI5AFfoVUTQ4ba",
    "xmw2rrQOub1Rq7137sFmp4",
    "DUUbzxyxa1pSbgmNNGjDvj",
    "vfhq54ZWSuw5hoCLDBnClO",
    "zxhwLumwWgVFHALSND1wIb",
    "erU4CVJZ0eXoHj2v8GZVfD",
    "BiXkzeIDM5z5EUSXo7c5cY",
    "LLM6sPiBcTRDr6ny06PfSY",
    "WAMAf8ni6h64dlMnknBDPO",
    "a2v0KyPIYUUFNAvUlopPJ6",
    "17XG2nBtxsF9kgq9LiMa8b",
    "5Rg0ikGmtQBWlmN5FVNPQp",
    "cELYYnvVYzdqSyHAEwJzeD",
    "poeYcuz7rAk39jVGGKGM1b",
    "YLgaYU1htNFDsmx0aH0vft",
    "m0r3yLrIISxbZekwHocAnR",
    "6VkCZTWvUgeTtG716BikAN",
    "bORNScKZHUcUz3D0l0x9nr",
    "aqxWlRTnxYHvXDNABhvWkd"
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}